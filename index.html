<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prompt Engineering & LLM Safety Specialist</title>
    <!-- Link external CSS file -->
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Prompt Engineering & AI Safety Specialist</h1>
        <p class="tagline">Expert in LLM Vulnerability Testing, Adversarial Prompt Engineering, and AI Red Teaming</p>
    </header>

    <section>
        <h2>Core Specializations</h2>
        <div class="skills-container">
            <span class="skill-badge">Prompt Engineering</span>
            <span class="skill-badge">Prompt Injection</span>
            <span class="skill-badge">Jailbreak Detection</span>
            <span class="skill-badge">AI Red Teaming</span>
            <span class="skill-badge">LLM Safety Testing</span>
            <span class="skill-badge">Adversarial Prompting</span>
            <span class="skill-badge">AI Alignment</span>
            <span class="skill-badge">LLM Guardrails</span>
            <span class="skill-badge">Content Policy Testing</span>
            <span class="skill-badge">Python</span>
        </div>
    </section>

    <section>
        <h2>Premium AI Safety Services</h2>
        
        <div class="service-card featured">
            <h3>Comprehensive LLM Security Assessment</h3>
            <p>I provide thorough security assessments for Large Language Models, identifying vulnerabilities in your AI systems before malicious actors do. My assessment includes systematic testing of content filters, jailbreak resistance, data protection measures, and prompt injection vulnerabilities.</p>
        </div>
        
        <div class="service-card featured">
            <h3>Advanced Prompt Engineering Solutions</h3>
            <p>I develop robust, jailbreak-resistant prompt templates and system instructions that help your AI behave exactly as intended while maintaining safety guardrails. This service includes direct prompt optimization, template hardening, and defense-in-depth prompt strategies.</p>
        </div>
        
        <div class="service-card">
            <h3>AI Red Team Exercises</h3>
            <p>I conduct comprehensive red team exercises against your AI systems, simulating real-world attacks through carefully crafted adversarial prompts. Each exercise concludes with detailed reports on vulnerabilities discovered and specific recommendations for mitigation.</p>
        </div>
        
        <div class="service-card">
            <h3>Custom Guardrail Development</h3>
            <p>I create tailored input/output filtering systems and prompt templates to protect your AI from misuse while maintaining functionality for legitimate use cases. Solutions range from rule-based systems to ML-based detectors for specific harmful patterns.</p>
        </div>
        
        <div class="service-card">
            <h3>Technical Documentation for AI Safety</h3>
            <p>I create clear, comprehensive safety documentation for AI systems, explaining complex security concepts and implementation details for both technical and non-technical stakeholders.</p>
        </div>
    </section>

    <section>
        <h2>Service Packages</h2>
        
        <div class="pricing-tier">
            <h3>Basic AI Safety Audit</h3>
            <span class="price-tag">$300-500</span>
            <p>A focused assessment of your AI system's core vulnerabilities, including:</p>
            <ul>
                <li>Testing against 25+ common prompt injection techniques</li>
                <li>Basic jailbreak resistance assessment</li>
                <li>Content policy compliance check</li>
                <li>Written report with key findings and recommendations</li>
            </ul>
            <p>Best for: Startups and smaller companies looking to ensure baseline AI safety.</p>
        </div>
        
        <div class="pricing-tier">
            <h3>Standard AI Red Team Exercise</h3>
            <span class="price-tag">$800-1200</span>
            <p>A comprehensive security assessment including:</p>
            <ul>
                <li>Testing against 50+ advanced prompt injection techniques</li>
                <li>In-depth jailbreak resistance testing</li>
                <li>Data leakage vulnerability assessment</li>
                <li>Model behavior boundary testing</li>
                <li>Detailed technical report with specific mitigation strategies</li>
            </ul>
            <p>Best for: Companies with customer-facing AI applications requiring robust security.</p>
        </div>
        
        <div class="pricing-tier">
            <h3>Prompt Engineering Optimization</h3>
            <span class="price-tag">$500-700</span>
            <p>Expert review and enhancement of your system prompts:</p>
            <ul>
                <li>Analysis of current system prompts and instructions</li>
                <li>Security-focused prompt optimization</li>
                <li>Development of hardened prompt templates</li>
                <li>Implementation of defense-in-depth prompt strategies</li>
            </ul>
            <p>Best for: Organizations looking to improve both safety and performance of existing AI systems.</p>
        </div>
    </section>

    <section>
        <h2>Selected Projects & Achievements</h2>
        
        <div class="project-card">
            <h3>LLM Vulnerability Research</h3>
            <p>Conducted research on adversarial prompts and LLM manipulation techniques, identifying novel methods to bypass safety filters in popular AI systems.</p>
            <div class="skills-container">
                <span class="skill-badge">LLM Security</span>
                <span class="skill-badge">Prompt Engineering</span>
                <span class="skill-badge">AI Safety</span>
            </div>
        </div>
        
        <div class="project-card">
            <h3>Cybersecurity Competition Achievements</h3>
            <p>Recognized performer in prestigious competitions including NCSC, RLCTF, and AIO, demonstrating practical skills in prompt hacking, exploit development, and AI security.</p>
            <div class="skills-container">
                <span class="skill-badge">Prompt Hacking</span>
                <span class="skill-badge">AI Security</span>
                <span class="skill-badge">Ethical Hacking</span>
            </div>
        </div>
        
        <div class="project-card">
            <h3>Injury Detection System</h3>
            <p>Developed an ML-powered system to detect and classify injuries using computer vision techniques, demonstrating practical machine learning implementation skills.</p>
            <div class="skills-container">
                <span class="skill-badge">Machine Learning</span>
                <span class="skill-badge">Computer Vision</span>
                <span class="skill-badge">Python</span>
            </div>
        </div>
    </section>

    <section>
        <h2>Certifications</h2>
        <div class="project-card">
            <h3>Prompt Engineering & Hacking Certification</h3>
            <p>Certified specialist in prompt engineering techniques and identifying vulnerabilities in AI systems.</p>
        </div>
    </section>

    <!-- Added Testimonials Section -->
    <section id="testimonials">
        <h2>Client Testimonials</h2>
        <div class="testimonial-card">
            <p>"[Placeholder for a future client quote. Describe the positive impact of your work here.]"</p>
            <p><strong>- [Client Name/Role, Company Name]</strong></p>
        </div>
        <!-- Add more testimonial-card divs as you collect them -->
        <p><em>More testimonials coming soon...</em></p>
    </section>

    <section>
        <h2>Why Work With Me</h2>
        <p>In today's AI landscape, <span class="highlight-text">security is often overlooked until it's too late</span>. As AI systems become more powerful, the risks of exploitation increase dramatically. I specialize exclusively in preventing these scenarios before they happen.</p>
        <p>By working with me, you get <span class="highlight-text">specialized expertise in AI safety</span> that general cybersecurity professionals rarely possess. I understand both the technical and ethical dimensions of AI safety, delivering practical solutions that keep your systems secure while maintaining their functionality.</p>
        
        <!-- Added CTA Button -->
        <div style="text-align: center; margin-top: 30px;"> <!-- Centering the button -->
             <a href="#contact" class="cta-button">Request a Consultation</a>
        </div>
    </section>

    <section id="contact"> <!-- Added id for linking -->
        <h2>Contact</h2>
        <p>Ready to secure your AI systems? For project inquiries or collaboration opportunities, please contact via [Parent-managed contact details - **Remember to replace this!**]</p>
        <p><small>Note: As a 17-year-old professional, all business arrangements are overseen by a parent/guardian in accordance with applicable regulations.</small></p>
    </section>

    <!-- Added Footer -->
    <footer>
        <p>&copy; [Year] [Your Name/Business Name]. All rights reserved.</p>
        <!-- Optional: Add link back to top or social links if desired -->
    </footer>

</body>
</html> 